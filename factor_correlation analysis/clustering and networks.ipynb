{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "\n",
    "#imports\n",
    "import pandas\n",
    "import numpy\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from factor_analyzer import FactorAnalyzer, calculate_kmo\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as pyplot\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================================\n",
    "\n",
    "#SETUP\n",
    "\n",
    "#set up file paths\n",
    "os.chdir('/Users/nsusser/Desktop/Github/happyDB/')\n",
    "\n",
    "#load data \n",
    "input_path = 'data/final data - main.csv'\n",
    "results = pandas.read_csv(input_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=========================================\n",
    "\n",
    "#PREPARE ITEMS\n",
    "\n",
    "#load items data\n",
    "items_path = 'dataframes/scales_clean.csv'\n",
    "items = pandas.read_csv(items_path)\n",
    "\n",
    "#clean and sanitize column names\n",
    "items['Scale'] = items['Scale'].str.strip().str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "items['Dimension'] = items['Dimension'].str.strip().str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "items['Items'] = items['Items'].str.strip().str.replace(r\"\\s+\", \"_\", regex=True)\n",
    "\n",
    "#create flattened column names\n",
    "cols = [f\"{scale}_{dimension}_{item}\" for scale, dimension, item in zip(\n",
    "    items['Scale'], items['Dimension'], items['Items']\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['PERMA_Accomplishment_the_speaker_felt_they_were_making_progress_towards_accomplishing_their_goals?',\n",
      "       'PERMA_Engagement_the_speaker_became_absorbed_in_what_they_were_doing?',\n",
      "       'PERMA_Positive_Emotion_the_speaker_felt_joyful?',\n",
      "       'PERMA_Negative_emotion_the_speaker_felt_anxious?',\n",
      "       'PERMA_Accomplishment_the_speaker_achieved_the_important_goals_they_set_for_themselves?',\n",
      "       'PERMA_Health_the_speaker_perceived_their_health_positively?',\n",
      "       'PERMA_Meaning_the_speaker_felt_their_life_was_purposeful_and_meaningful?',\n",
      "       'PERMA_Relationships_the_speaker_received_help_and_support_from_others_when_needed?',\n",
      "       'PERMA_Meaning_the_speaker_felt_what_they_did_in_life_was_valuable_and_worthwhile?',\n",
      "       'PERMA_Engagement_the_speaker_felt_excited_and_interested_in_things?',\n",
      "       ...\n",
      "       'CIT_Optimism_the_speaker_expected_more_good_things_in_their_life_than_bad?',\n",
      "       'CIT_Subjective_Well-Being_-_Life_Satisfaction_the_speaker_felt_in_most_ways_their_life_was_close_to_their_ideal?',\n",
      "       'CIT_Subjective_Well-Being_-_Life_Satisfaction_the_speaker_felt_satisfied_with_their_life?',\n",
      "       'CIT_Subjective_Well-Being_-_Life_Satisfaction_the_speaker_felt_their_life_is_going_well?',\n",
      "       'CIT_Subjective_Well-Being_-_Positive_Feelings_the_speaker_felt_positive_most_of_the_time?',\n",
      "       'CIT_Subjective_Well-Being_-_Positive_Feelings_the_speaker_felt_happy_most_of_the_time?',\n",
      "       'CIT_Subjective_Well-Being_-_Positive_Feelings_the_speaker_felt_good_most_of_the_time?',\n",
      "       'CIT_Subjective_Well-Being_-_Negative_Feelings_the_speaker_felt_negative_most_of_the_time?',\n",
      "       'CIT_Subjective_Well-Being_-_Negative_Feelings_the_speaker_experienced_unhappy_feelings_most_of_the_time?',\n",
      "       'CIT_Subjective_Well-Being_-_Negative_Feelings_the_speaker_felt_bad_most_of_the_time?'],\n",
      "      dtype='object', length=197)\n"
     ]
    }
   ],
   "source": [
    "#=========================================\n",
    "\n",
    "#SUBSET DATA\n",
    "\n",
    "#subset df with cols\n",
    "df_subset = results[cols]\n",
    "print(df_subset.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nsusser/Desktop/Github/happyDB/viz-env/lib/python3.13/site-packages/factor_analyzer/utils.py:244: UserWarning: The inverse of the variance-covariance matrix was calculated using the Moore-Penrose generalized matrix inversion, due to its determinant being at or very close to zero.\n",
      "  warnings.warn(\n",
      "/Users/nsusser/Desktop/Github/happyDB/viz-env/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/nsusser/Desktop/Github/happyDB/viz-env/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/nsusser/Desktop/Github/happyDB/viz-env/lib/python3.13/site-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#=========================================\n",
    "\n",
    "#FACTOR ANALYSIS\n",
    "\n",
    "#standardize df_subset\n",
    "scaler = StandardScaler()\n",
    "df_subset = pandas.DataFrame(scaler.fit_transform(df_subset), columns=df_subset.columns)\n",
    "\n",
    "#calculate kmo and bartlett's test\n",
    "kmo_all, kmo_model = calculate_kmo(df_subset)\n",
    "\n",
    "#determine optimal number of factors\n",
    "fa = FactorAnalyzer(rotation=None)\n",
    "fa.fit(df_subset)\n",
    "eigenvalues, _ = fa.get_eigenvalues()\n",
    "\n",
    "#fit factor analysis with optimal factors\n",
    "optimal_factors = sum(eigenvalues > 1) #or based on scree plot\n",
    "fa = FactorAnalyzer(n_factors=optimal_factors, rotation='varimax')\n",
    "fa.fit(df_subset)\n",
    "\n",
    "#project cols onto factors\n",
    "factor_scores = fa.transform(df_subset)\n",
    "for i in range(factor_scores.shape[1]):\n",
    "    results[f'Factor_{i+1}'] = factor_scores[:, i]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(197, 21)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nfor i in range(factor_loadings.shape[1]):\\n    sorted_loadings = factor_loadings.iloc[:, i].abs().sort_values(ascending=False)\\n    top_variables = sorted_loadings.head(10).index.tolist()\\n    print(f'Factor {i+1}: {top_variables}')\\n\\n\\n# Create an empty list to store the results\\nfactor_loading_results = []\\n\\n# Iterate through each factor's loadings\\nfor i in range(factor_loadings.shape[1]):\\n    sorted_loadings = factor_loadings.iloc[:, i].abs().sort_values(ascending=False)\\n    top_variables = sorted_loadings.head(10).index.tolist()\\n    top_loadings = sorted_loadings.head(10).values.tolist()\\n    \\n    # Append each factor's results to the list\\n    for var, loading in zip(top_variables, top_loadings):\\n        factor_loading_results.append({\\n            'Factor': f'Factor {i+1}',\\n            'Variable': var,\\n            'Loading': loading\\n        })\\n\\n# Convert the results to a DataFrame\\nfactor_loading_df = pd.DataFrame(factor_loading_results)\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print top ten\n",
    "variable_name_mapping = dict(zip(cols, items)) #map cols to variable names\n",
    "factor_loadings = pd.DataFrame(fa.loadings_, index=items)\n",
    "\n",
    "# print factor loadings\n",
    "print(factor_loadings.shape)\n",
    "\n",
    "'''\n",
    "for i in range(factor_loadings.shape[1]):\n",
    "    sorted_loadings = factor_loadings.iloc[:, i].abs().sort_values(ascending=False)\n",
    "    top_variables = sorted_loadings.head(10).index.tolist()\n",
    "    print(f'Factor {i+1}: {top_variables}')\n",
    "\n",
    "\n",
    "# Create an empty list to store the results\n",
    "factor_loading_results = []\n",
    "\n",
    "# Iterate through each factor's loadings\n",
    "for i in range(factor_loadings.shape[1]):\n",
    "    sorted_loadings = factor_loadings.iloc[:, i].abs().sort_values(ascending=False)\n",
    "    top_variables = sorted_loadings.head(10).index.tolist()\n",
    "    top_loadings = sorted_loadings.head(10).values.tolist()\n",
    "    \n",
    "    # Append each factor's results to the list\n",
    "    for var, loading in zip(top_variables, top_loadings):\n",
    "        factor_loading_results.append({\n",
    "            'Factor': f'Factor {i+1}',\n",
    "            'Variable': var,\n",
    "            'Loading': loading\n",
    "        })\n",
    "\n",
    "# Convert the results to a DataFrame\n",
    "factor_loading_df = pd.DataFrame(factor_loading_results)'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viz-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
